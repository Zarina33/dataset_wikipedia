#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–æ–ø—Ä–æ—Å–æ–≤-–æ—Ç–≤–µ—Ç–æ–≤ –∏–∑ —Å—Ç–∞—Ç–µ–π Wikipedia —Å –ø–æ–º–æ—â—å—é Gemini API
"""

import pandas as pd
import json
import time
import logging
from typing import Dict, List, Optional
import os
from tqdm import tqdm
import copy
import google.generativeai as genai
from google.api_core import exceptions as google_exceptions
from dotenv import load_dotenv

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('qa_generation.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è API –∫–ª—é—á–∞–º–∏ –∏ –º–æ–¥–µ–ª—è–º–∏
API_KEYS = []
MODEL_LIST = ["gemini-2.5-flash",
        "gemini-2.5-flash-lite",
        "gemini-2.5-pro",
        "gemini-2.0-flash-lite",
        "gemini-2.0-flash", "gemini-1.5-pro"]
current_api_key_index = 0
current_model_index = 0
model = None

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã
MAX_REQUESTS_PER_RUN = 5000
REQUEST_DELAY_SECONDS = 2  # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏


class InvalidApiResponseError(Exception):
    """–ò—Å–∫–ª—é—á–µ–Ω–∏–µ –¥–ª—è —Å–ª—É—á–∞–µ–≤, –∫–æ–≥–¥–∞ API –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π JSON."""

    def __init__(self, message, response_text):
        super().__init__(message)
        self.response_text = response_text


class WikipediaQAGenerator:
    def __init__(self):
        self.requests_count = 0

    def load_and_configure_keys(self) -> bool:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–ª—é—á–∏ –∏–∑ .env –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–µ—Ä–≤—É—é –º–æ–¥–µ–ª—å –∏–∑ —Å–ø–∏—Å–∫–∞."""
        global API_KEYS, current_api_key_index, current_model_index, model

        load_dotenv()
        api_key_names = [key for key in os.environ if key.startswith("GOOGLE_API_KEY_")]
        api_key_names.sort()
        API_KEYS = [os.getenv(key) for key in api_key_names]

        if not API_KEYS:
            logger.error("–ù–µ –Ω–∞–π–¥–µ–Ω—ã –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è —Ñ–æ—Ä–º–∞—Ç–∞ GOOGLE_API_KEY_1, GOOGLE_API_KEY_2 –∏ —Ç.–¥.")
            return False

        logger.info(f"üîë –ù–∞–π–¥–µ–Ω–æ {len(API_KEYS)} API –∫–ª—é—á–µ–π.")
        logger.info(f"üß† –°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è: {MODEL_LIST}")

        current_api_key_index = 0
        current_model_index = 0

        try:
            genai.configure(api_key=API_KEYS[current_api_key_index])
            model_name = MODEL_LIST[current_model_index]
            model = genai.GenerativeModel(model_name=model_name)
            logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å –∫–ª—é—á–æ–º #1 –∏ –º–æ–¥–µ–ª—å—é '{model_name}'")
            return True
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —Å –ø–µ—Ä–≤—ã–º –∫–ª—é—á–æ–º –∏ –º–æ–¥–µ–ª—å—é: {e}")
            return self.switch_model_or_key()

    def switch_model_or_key(self) -> bool:
        """
        –ü–µ—Ä–µ–∫–ª—é—á–∞–µ—Ç—Å—è –Ω–∞ —Å–ª–µ–¥—É—é—â—É—é –º–æ–¥–µ–ª—å –≤ —Å–ø–∏—Å–∫–µ. –ï—Å–ª–∏ –≤—Å–µ –º–æ–¥–µ–ª–∏ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –∫–ª—é—á–∞
        –∏—Å–ø—Ä–æ–±–æ–≤–∞–Ω—ã, –ø–µ—Ä–µ–∫–ª—é—á–∞–µ—Ç—Å—è –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–π API –∫–ª—é—á –∏ –Ω–∞—á–∏–Ω–∞–µ—Ç —Å –ø–µ—Ä–≤–æ–π –º–æ–¥–µ–ª–∏.
        """
        global current_api_key_index, current_model_index, model

        # –ü—ã—Ç–∞–µ–º—Å—è –ø–µ—Ä–µ–∫–ª—é—á–∏—Ç—å—Å—è –Ω–∞ —Å–ª–µ–¥—É—é—â—É—é –º–æ–¥–µ–ª—å —Å —Ç–µ–∫—É—â–∏–º –∫–ª—é—á–æ–º
        current_model_index += 1
        if current_model_index < len(MODEL_LIST):
            model_name = MODEL_LIST[current_model_index]
            key_index_for_log = current_api_key_index + 1
            logger.info(f"üîÑ –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ –º–æ–¥–µ–ª—å '{model_name}' —Å –∫–ª—é—á–æ–º #{key_index_for_log}...")
            try:
                model = genai.GenerativeModel(model_name=model_name)
                logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å –º–æ–¥–µ–ª—å—é '{model_name}'")
                return True
            except Exception as e:
                logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å '{model_name}' —Å –∫–ª—é—á–æ–º #{key_index_for_log}: {e}")
                return self.switch_model_or_key()

        # –ï—Å–ª–∏ –≤—Å–µ –º–æ–¥–µ–ª–∏ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –∫–ª—é—á–∞ –∏—Å—á–µ—Ä–ø–∞–Ω—ã, –ø–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–π –∫–ª—é—á
        current_api_key_index += 1
        if current_api_key_index < len(API_KEYS):
            key_index_for_log = current_api_key_index + 1
            logger.info(f"üîÑ –í—Å–µ –º–æ–¥–µ–ª–∏ –∏—Å—á–µ—Ä–ø–∞–Ω—ã –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –∫–ª—é—á–∞. –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ API –∫–ª—é—á #{key_index_for_log}...")

            # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –∏–Ω–¥–µ–∫—Å –º–æ–¥–µ–ª–µ–π
            current_model_index = 0
            model_name = MODEL_LIST[current_model_index]

            try:
                genai.configure(api_key=API_KEYS[current_api_key_index])
                model = genai.GenerativeModel(model_name=model_name)
                logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å –∫–ª—é—á–æ–º #{key_index_for_log} –∏ –º–æ–¥–µ–ª—å—é '{model_name}'")
                return True
            except Exception as e:
                logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–ª—é—á #{key_index_for_log} —Å –º–æ–¥–µ–ª—å—é '{model_name}': {e}")
                return self.switch_model_or_key()
        else:
            logger.critical("üö´ –í—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ –∏ API –∫–ª—é—á–∏ –∏—Å—á–µ—Ä–ø–∞–ª–∏ —Å–≤–æ–∏ –ª–∏–º–∏—Ç—ã.")
            return False

    def generate_qa_from_text(self, text: str) -> Optional[Dict[str, str]]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–æ–ø—Ä–æ—Å–∞ –∏ –æ—Ç–≤–µ—Ç–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å—Ç–∞—Ç—å–∏"""
        global model

        if self.requests_count >= MAX_REQUESTS_PER_RUN:
            logger.warning(f"–î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ ({MAX_REQUESTS_PER_RUN})")
            return None

        # –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
        cleaned_text = text.strip().replace('"', '').replace('\n', ' ')

        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        if len(cleaned_text) > 5000:
            cleaned_text = cleaned_text[:5000] + "..."

        prompt = f"""Generate a natural question-answer pair in Kyrgyz language for training data collection.

        Text: {cleaned_text}

        Instructions:
        1. Analyze the content and create a broad, contextual question about the main topic:
           - Focus on the SUBJECT/THEME rather than specific objects ("this book", "this document")
           - Ask about general concepts, processes, or categories mentioned
           - Avoid questions that assume specific context unknown to the reader

        2. Question generation logic:
           - If content lists items ‚Üí "What are the main [category] in [field/area]?"
           - If content explains process ‚Üí "How does [process] work?"
           - If content describes concept ‚Üí "What is [concept]?"
           - If content gives overview ‚Üí "What can you tell about [topic area]?"

        3. Answer requirements:
           - Transform the original text into a natural response
           - Remove any references to specific documents/sources
           - Make minimal grammatical corrections only
           - Present information as general knowledge, not as "this text says"

        4. Language requirements:
           - Use only Kyrgyz language
           - Make both question and answer sound completely natural
           - Never reference source ("–±—É–ª –∫–∏—Ç–µ–ø—Ç–µ", "–¥–æ–∫—É–º–µ–Ω—Ç—Ç–µ", "—Ç–µ–∫—Å—Ç–µ")
           - Ensure proper Kyrgyz grammar and sentence flow

        5. Example transformations:
           - Bad: "–ë—É–ª –∫–∏—Ç–µ–ø—Ç–µ –∫–∞–Ω–¥–∞–π —ã—Ä—á—ã–ª–∞—Ä –±–∞—Ä?" 
           - Good: "–ö—ã—Ä–≥—ã–∑—Å—Ç–∞–Ω–¥—ã–Ω –±–µ–ª–≥–∏–ª“Ø“Ø –∫–æ–º–ø–æ–∑–∏—Ç–æ—Ä–ª–æ—Ä—É –∂–∞–Ω–∞ —ã—Ä—á—ã–ª–∞—Ä—ã –∫–∏–º–¥–µ—Ä?"

        Return response in strict JSON format:
        {{
            "question": "your natural question here",
            "answer": "your comprehensive answer here"
        }}"""

        try:
            response = model.generate_content(prompt)
            self.requests_count += 1

            if response.text:
                cleaned_response = response.text.strip()
                qa_pair = self.parse_qa_response(cleaned_response)
                return qa_pair
            else:
                logger.error("API –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç")
                return None

        except (google_exceptions.ResourceExhausted, google_exceptions.PermissionDenied,
                google_exceptions.InvalidArgument) as e:
            logger.warning(f"–ü—Ä–æ–±–ª–µ–º–∞ —Å API: {e}. –ü–æ–ø—ã—Ç–∫–∞ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è...")
            if self.switch_model_or_key():
                # –ü–æ–≤—Ç–æ—Ä—è–µ–º –∑–∞–ø—Ä–æ—Å —Å –Ω–æ–≤—ã–º –∫–ª—é—á–æ–º/–º–æ–¥–µ–ª—å—é
                return self.generate_qa_from_text(text)
            else:
                return None
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ Gemini API: {e}")
            return None

    def parse_qa_response(self, response_text: str) -> Optional[Dict[str, str]]:
        """–ü–∞—Ä—Å–∏–Ω–≥ JSON –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª–∏ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –≤–æ–ø—Ä–æ—Å–∞ –∏ –æ—Ç–≤–µ—Ç–∞"""
        try:
            # –û—á–∏—Å—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞ –æ—Ç –≤–æ–∑–º–æ–∂–Ω—ã—Ö markdown –±–ª–æ–∫–æ–≤
            cleaned_response = response_text.strip().lstrip("```json").rstrip("```").strip()

            # –ü–æ–ø—ã—Ç–∫–∞ –Ω–∞–π—Ç–∏ JSON –≤ –æ—Ç–≤–µ—Ç–µ
            json_start = cleaned_response.find('{')
            json_end = cleaned_response.rfind('}') + 1

            if json_start != -1 and json_end > json_start:
                json_str = cleaned_response[json_start:json_end]
                try:
                    qa_data = json.loads(json_str)
                    if 'question' in qa_data and 'answer' in qa_data:
                        return {
                            "question": qa_data['question'].strip(),
                            "answer": qa_data['answer'].strip()
                        }
                except json.JSONDecodeError:
                    pass

            # Fallback: –ø–æ–ø—ã—Ç–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—Ç–∞—Ä–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞
            lines = response_text.split('\n')
            question = None
            answer = None

            for line in lines:
                line = line.strip()
                if line.startswith('–°—É—Ä–æ–æ:'):
                    question = line.replace('–°—É—Ä–æ–æ:', '').strip()
                elif line.startswith('–ñ–æ–æ–ø:'):
                    answer = line.replace('–ñ–æ–æ–ø:', '').strip()
                    # –°–æ–±–∏—Ä–∞–µ–º –º–Ω–æ–≥–æ—Å—Ç—Ä–æ—á–Ω—ã–π –æ—Ç–≤–µ—Ç
                    idx = lines.index(line)
                    if idx < len(lines) - 1:
                        remaining_lines = lines[idx + 1:]
                        for remaining_line in remaining_lines:
                            remaining_line = remaining_line.strip()
                            if remaining_line and not remaining_line.startswith('–°—É—Ä–æ–æ:'):
                                answer += ' ' + remaining_line
                            else:
                                break

            if question and answer:
                return {
                    "question": question,
                    "answer": answer
                }
            else:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –æ—Ç–≤–µ—Ç: {response_text}")
                raise InvalidApiResponseError(
                    "Failed to parse QA response",
                    response_text=response_text
                )

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞: {e}")
            return None

    def process_csv_file(self, csv_file_path: str, output_file_path: str,
                         start_from: int = 0, max_articles: Optional[int] = None):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ CSV —Ñ–∞–π–ª–∞ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞ Q&A"""

        if not os.path.exists(csv_file_path):
            logger.error(f"CSV —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {csv_file_path}")
            return

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è API –∫–ª—é—á–µ–π
        if not self.load_and_configure_keys():
            logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å Gemini API")
            return

        logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ CSV —Ñ–∞–π–ª–∞: {csv_file_path}")

        try:
            # –ó–∞–≥—Ä—É–∑–∫–∞ CSV —Ñ–∞–π–ª–∞
            df = pd.read_csv(csv_file_path)
            logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} —Å—Ç–∞—Ç–µ–π")

            # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
            df = df.dropna(subset=['Text'])
            df = df[df['Text'].str.len() > 50]

            # –ó–∞–≥—Ä—É–∑–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            qa_dataset = []
            processed_indices = set()

            if os.path.exists(output_file_path):
                try:
                    with open(output_file_path, 'r', encoding='utf-8') as f:
                        qa_dataset = json.load(f)

                    for item in qa_dataset:
                        if 'source_index' in item:
                            processed_indices.add(item['source_index'])

                    logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(qa_dataset)} —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö Q&A –ø–∞—Ä")

                    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ–º, —Å –∫–∞–∫–æ–π —Å—Ç–∞—Ç—å–∏ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å
                    if processed_indices:
                        last_processed = max(processed_indices)
                        if start_from <= last_processed:
                            start_from = last_processed + 1
                            logger.info(f"üîÑ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å —Å—Ç–∞—Ç—å–∏ {start_from}")

                except Exception as e:
                    logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ñ–∞–π–ª: {e}")

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω –æ–±—Ä–∞–±–æ—Ç–∫–∏
            if max_articles:
                end_idx = min(start_from + max_articles, len(df))
            else:
                end_idx = len(df)

            articles_to_process = df.iloc[start_from:end_idx]
            logger.info(f"–ë—É–¥–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å—Ç–∞—Ç–µ–π: {len(articles_to_process)} (—Å {start_from} –ø–æ {end_idx - 1})")

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç–∞—Ç–µ–π
            successful_generations = 0
            failed_generations = 0

            with tqdm(total=len(articles_to_process), desc="–ì–µ–Ω–µ—Ä–∞—Ü–∏—è Q&A") as pbar:
                for idx, row in articles_to_process.iterrows():
                    if self.requests_count >= MAX_REQUESTS_PER_RUN:
                        logger.warning(f"–î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ ({MAX_REQUESTS_PER_RUN})")
                        break

                    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Å—Ç–∞—Ç—å–∏
                    if idx in processed_indices:
                        pbar.set_description(f"–ü—Ä–æ–ø—É—Å–∫ —Å—Ç–∞—Ç—å–∏ {idx} (—É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞)")
                        pbar.update(1)
                        continue

                    text = row['Text']
                    pbar.set_description(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç–∞—Ç—å–∏ {idx}")

                    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è Q&A –ø–∞—Ä—ã
                    qa_pair = self.generate_qa_from_text(text)

                    if qa_pair:
                        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
                        qa_pair['source_index'] = int(idx)
                        qa_pair['source_text_length'] = len(text)
                        qa_pair['generated_at'] = time.strftime('%Y-%m-%d %H:%M:%S')

                        qa_dataset.append(qa_pair)
                        successful_generations += 1

                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                        if successful_generations % 5 == 0:
                            self.save_dataset(qa_dataset, output_file_path)
                            logger.info(f"–ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ: {successful_generations} Q&A –ø–∞—Ä")
                    else:
                        failed_generations += 1
                        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å Q&A –¥–ª—è —Å—Ç–∞—Ç—å–∏ {idx}")

                    pbar.update(1)

                    # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                    if self.requests_count < MAX_REQUESTS_PER_RUN:
                        time.sleep(REQUEST_DELAY_SECONDS)

            # –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
            self.save_dataset(qa_dataset, output_file_path)

            logger.info(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
            logger.info(f"–£—Å–ø–µ—à–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ: {successful_generations} Q&A –ø–∞—Ä")
            logger.info(f"–û—à–∏–±–æ–∫: {failed_generations}")
            logger.info(f"–í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ API: {self.requests_count}")
            logger.info(f"–í—Å–µ–≥–æ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ: {len(qa_dataset)} Q&A –ø–∞—Ä")
            logger.info(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_file_path}")

        except Exception as e:
            logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞: {e}")
            raise

    def save_dataset(self, dataset: List[Dict], output_file_path: str):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –≤ JSON —Ñ–∞–π–ª"""
        try:
            with open(output_file_path, 'w', encoding='utf-8') as f:
                json.dump(dataset, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {e}")
            raise


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    generator = WikipediaQAGenerator()

    # –ü—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º
    csv_file = "kyrgyz_wikipedia_data.csv"
    output_file = "kyrgyz_wikipedia_qa_datasetGEMINI.jsonl"

    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏
    start_from = 7545  # –ù–∞—á–∞—Ç—å —Å –∫–∞–∫–æ–π —Å—Ç–∞—Ç—å–∏ (–¥–ª—è –≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏—è)
    max_articles = None  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–∞—Ç–µ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (None = –í–°–ï —Å—Ç–∞—Ç—å–∏!)

    try:
        generator.process_csv_file(
            csv_file_path=csv_file,
            output_file_path=output_file,
            start_from=start_from,
            max_articles=max_articles
        )
    except KeyboardInterrupt:
        logger.info("–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")


if __name__ == "__main__":
    main()
